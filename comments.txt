Привет, Саша!
Спасибо за твои ответы!
Еще раз прошу меня простить, но этот спринт для меня тяжеловат(
Обычно я стараюсь не отправлять на выходных
Но на следующей неделе очень мало рабочих дней, поэтому сорри
С проверкой не спеши, если у нас нет жесткого kpi то я подожду

По слою dds
    Перенес из урока DDL скрипт для таблицы в dds (DDL_dds.sql)

    В файле обработки приложения dds_message_processor_job.py сделана заготовка класса DdsMessageProcessor
        но мне немного непонятно как создавать новый топик,     
        в файле solution/service_dds/src/app_config.py уже настроен self.kafka_producer_topic = str(os.getenv('KAFKA_DESTINATION_TOPIC'))
        нужно ли мне просто заменить kafka_producer_topic на другой, из которого потом будет вычитывать следующий слой?

    Создан файл repository.dds_repository
        Есть вопрос по работе с продуктами
        Как я понимаю каждый продукт заказа очень индивидуален
    и в случае измення аттрибутов или у продукта будет новый id
    или же мы работаем с верионной формата таблицей SCD1 и новые аттрибуты перезаписывают прошлые

        Немного непонятно чем заполнять поле load_src в нашей таблице dds

        Поля hk_user_names_pk, hk_product_names_pk, hk_restaurant_names_pk
        нужно заполнять как hash() id их сущностей? 
        и отдельно поле h_category_pk его нужно формировать через hash() имени категории?


По слою cdm
    Перенес из урока DDL скрипт для таблицы в dds (DDL_cdm.sql)

    В файле обработки приложения cdm_message_processor_job.py сделана заготовка класса CdmMessageProcessor
        или я доблен поправить конфиги или прописать данные прям в файле, но первое представляется мне более правильным
    
    В самом классе CdmRepository сомневаюсь в правильности логики
    ON CONFLICT (user_id, product_id) DO UPDATE SET order_cnt = EXCLUDED.order_cnt + 1;

 
Пока на этом все!
Буду ждать твою проверку и рад замечаниям!
Успехов!